{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "CNDKREiQRJJX",
      "metadata": {
        "id": "CNDKREiQRJJX"
      },
      "source": [
        "<font size=\"+3\"><b>Non-Linear Models and Validation Metrics</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce31b39a",
      "metadata": {
        "id": "ce31b39a"
      },
      "source": [
        "<font color='Red'>\n",
        "In this project, we will need to write code that uses non-linear models to perform classification and regression tasks. We will also be describing the process by whichthe code was written. More details can be found below. Any websites or AI tools used will be cited, if used.</font>\n",
        "\n",
        "NOTE: You may use the Table of Content on the left side of this notebook to efficiently navigate within this document/project.\n",
        "\n",
        "---\n",
        "\n",
        "|                **Question**                |\n",
        "|:------------------------------------------:|\n",
        "|           **Part 1: Regression**           |  \n",
        "|          Step 0: Import Libraries          |          \n",
        "|             Step 1: Data Input             |    \n",
        "|           Step 2: Data Processing          |     \n",
        "| Step 3: Implement   Machine Learning Model |    \n",
        "|           Step 4: Validate Model           |    \n",
        "|         Step 5: Visualize   Results        |     \n",
        "|                  Questions                 |    \n",
        "|             Process Description            |     \n",
        "|         **Part 2: Classification**         |\n",
        "|             Step 1: Data Input             |    \n",
        "|           Step 2: Data Processing          |    \n",
        "| Step 3: Implement   Machine Learning Model |           \n",
        "|            Step 4: Validate Mode           |           \n",
        "|         Step 5: Visualize   Results        |    \n",
        "|                  Questions                 |     \n",
        "|             Process Description            |\n",
        "|         **Part 3: LinearSVC**         |  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf275ca7",
      "metadata": {
        "id": "cf275ca7"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2b67a661",
      "metadata": {
        "id": "2b67a661"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ee2d2c3",
      "metadata": {
        "id": "5ee2d2c3"
      },
      "source": [
        "# **Part 1: Regression**\n",
        "\n",
        "For this section, we will be continuing with the concrete example from yellowbrick. We will be comparing these results to the results from the project 1, where we used linear models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8219f163",
      "metadata": {
        "id": "8219f163"
      },
      "source": [
        "## **Step 1:** Data Input\n",
        "\n",
        "The data used for this task can be downloaded using the yellowbrick library:\n",
        "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
        "\n",
        "Using the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2af8bd32",
      "metadata": {
        "id": "2af8bd32"
      },
      "outputs": [],
      "source": [
        "# Import concrete dataset from yellowbrick library\n",
        "from yellowbrick.datasets import load_concrete\n",
        "\n",
        "# Load the concrete dataset\n",
        "X, y = load_concrete()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42fea4cc",
      "metadata": {
        "id": "42fea4cc"
      },
      "source": [
        "## **Step 2:** Data Processing\n",
        "\n",
        "Data processing was completed in the previous project already. We do not need to repeat that here again."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a245d00",
      "metadata": {
        "id": "2a245d00"
      },
      "source": [
        "## **Step 3:** Implement Machine Learning Model\n",
        "\n",
        "1. Importing the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
        "2. Instantiating the three models with `max_depth = 5`\n",
        "3. Implementing each machine learning model with `X` and `y`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f994e31",
      "metadata": {
        "id": "3f994e31"
      },
      "source": [
        "## **Step 4:** Validate Model\n",
        "\n",
        "Calculating the average training and validation accuracy using mean squared error with cross-validation. To do this, we will be setting `scoring='neg_mean_squared_error'` in our `cross_validate` function and will negate the results (multiply by -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fc3f7a8",
      "metadata": {
        "id": "5fc3f7a8"
      },
      "source": [
        "## **Step 5:** Visualize Results\n",
        "\n",
        "1. Creating a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
        "2. Adding the accuracy results to the `results` DataFrame\n",
        "3. Printing `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fdc93a78",
      "metadata": {
        "id": "fdc93a78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Training accuracy  Validation accuracy\n",
            "DT          30.804969           244.559027\n",
            "RF          22.009196           233.010203\n",
            "GB           2.100764           157.240330\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Instantiating the models\n",
        "dt_model = DecisionTreeRegressor(max_depth=5, random_state=0)\n",
        "rf_model = RandomForestRegressor(max_depth=5, random_state=0, n_estimators=100)\n",
        "gb_model = GradientBoostingRegressor(max_depth=5, random_state=0, n_estimators=100, learning_rate=0.1)\n",
        "\n",
        "# Implementing each machine learning model\n",
        "# dt_model.fit(X, y)\n",
        "# rf_model.fit(X, y)\n",
        "# gb_model.fit(X, y)\n",
        "\n",
        "# Defining the scoring metric for cross-validation (repetitive code)\n",
        "scoring_var = 'neg_mean_squared_error'\n",
        "\n",
        "# Performing cross-validation for each model\n",
        "dt_scores = cross_validate(dt_model, X, y, scoring=scoring_var, cv=2, return_train_score=True)\n",
        "rf_scores = cross_validate(rf_model, X, y, scoring=scoring_var, cv=2, return_train_score=True)\n",
        "gb_scores = cross_validate(gb_model, X, y, scoring=scoring_var, cv=2, return_train_score=True)\n",
        "\n",
        "# Calculating the average training and validation accuracy\n",
        "dt_train_avg = dt_scores['train_score'].mean()\n",
        "dt_test_avg = dt_scores['test_score'].mean()\n",
        "\n",
        "rf_train_avg = rf_scores['train_score'].mean()\n",
        "rf_test_avg = rf_scores['test_score'].mean()\n",
        "\n",
        "gb_train_avg = gb_scores['train_score'].mean()\n",
        "gb_test_avg = gb_scores['test_score'].mean()\n",
        "\n",
        "tmp_results_test= [dt_test_avg, rf_test_avg, gb_test_avg]\n",
        "tmp_results_train = [dt_train_avg, rf_train_avg, gb_train_avg]\n",
        "new_results_train, new_results_test = [], []\n",
        "\n",
        "for i in range(len(tmp_results_test)):\n",
        "    new_results_train.append(tmp_results_train[i] * -1)\n",
        "    new_results_test.append(tmp_results_test[i] * -1)\n",
        "\n",
        "# Creating a pandas DataFrame to store the results\n",
        "results = pd.DataFrame({\"Training accuracy\": new_results_train, \"Validation accuracy\": new_results_test}, index=['DT', 'RF', 'GB'])\n",
        "\n",
        "# Printing the results\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31715a9d",
      "metadata": {
        "id": "31715a9d"
      },
      "source": [
        "Repeating the step above to print the R2 score instead of the mean-squared error. For this case, we can now use `scoring='r2'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "83539f47",
      "metadata": {
        "id": "83539f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Training accuracy  Validation accuracy\n",
            "DT           0.867502            -0.080545\n",
            "RF           0.905799            -0.030577\n",
            "GB           0.991863             0.308657\n"
          ]
        }
      ],
      "source": [
        "# Defining the scoring metric for cross-validation (repetitive code)\n",
        "scoring_var = 'r2'\n",
        "\n",
        "# Performing cross-validation for each model with r2 scoring\n",
        "dt_scores_r2 = cross_validate(dt_model, X, y, scoring=scoring_var, cv=2, return_train_score=True)\n",
        "rf_scores_r2 = cross_validate(rf_model, X, y, scoring=scoring_var, cv=2, return_train_score=True)\n",
        "gb_scores_r2 = cross_validate(gb_model, X, y, scoring=scoring_var, cv=2, return_train_score=True)\n",
        "\n",
        "# Calculating the average training and validation accuracy\n",
        "dt_train_avg = dt_scores_r2['train_score'].mean()\n",
        "dt_test_avg = dt_scores_r2['test_score'].mean()\n",
        "\n",
        "rf_train_avg = rf_scores_r2['train_score'].mean()\n",
        "rf_test_avg = rf_scores_r2['test_score'].mean()\n",
        "\n",
        "gb_train_avg = gb_scores_r2['train_score'].mean()\n",
        "gb_test_avg = gb_scores_r2['test_score'].mean()\n",
        "\n",
        "tmp_results_test= [dt_test_avg, rf_test_avg, gb_test_avg]\n",
        "tmp_results_train = [dt_train_avg, rf_train_avg, gb_train_avg]\n",
        "new_results_train, new_results_test = [], []\n",
        "\n",
        "for i in range(len(tmp_results_test)):\n",
        "    new_results_train.append(tmp_results_train[i])\n",
        "    new_results_test.append(tmp_results_test[i])\n",
        "\n",
        "# Creating a pandas DataFrame to store the results\n",
        "results_r2 = pd.DataFrame({\"Training accuracy\": new_results_train, \"Validation accuracy\": new_results_test}, index=['DT', 'RF', 'GB'])\n",
        "\n",
        "# Printing the results\n",
        "print(results_r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5257a98",
      "metadata": {
        "id": "a5257a98"
      },
      "source": [
        "## **Practice descriptive questions & answers for theoratical understanding**\n",
        "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
        "1. Out of the models you tested, which model would you select for this dataset and why?\n",
        "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2PRnpiFjVDzv",
      "metadata": {
        "id": "2PRnpiFjVDzv"
      },
      "source": [
        "<font color='Green'><b>\n",
        "1. The results obtained using non-linear models (Decision Tree, Random Forest, and Gradient Boosting) are of course expected to be different from the results obtained using a linear model, as we did in assignment 2. Since linear model assumes a linear relationship between the features and the target variable and non-linear models capture more complex relationships, the non-linear models are expected to perform better than the linear model. However, results are very poor in this case. The R2 score on the previous assignment was 0.636898 but the score on this assignment is achieved to be -0.080545 for the Decision Tree model. Additionally, the Random Forest model achieved a score of -0.030577 and the Gradient Boosting model achieved a score of 0.308657. It can be observed clearly that there is a significant drop here and even negative values for some, showing that the non-linear models are not performing well at all on this dataset. \n",
        "\n",
        "2. Based on the results obtained above, the model that has the highest validation accuracy is Gradient Boosted Trees (GB) as opposed to the performances of the Decision Tree (DT) and Random Forest (RF) models. With better generalization performance, it even has a higher training accuracy as compared to other 2.\n",
        "\n",
        "3. To increase the accuracy of these tree-based models, we might want to imlement the following strategies:\n",
        "   - Increase the depth of the trees by increasing the `max_depth` parameter, the trees can capture more complex relationships in the data. However, there will be a great chance for overfitting the training data.\n",
        "   - Adjust the hyperparameters by trying different hyperparameter values, such as the number of estimators (`n_estimators`), learning rate (`learning_rate`), and other parameters specific to each model.\n",
        "</b></font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37b238f4",
      "metadata": {
        "id": "37b238f4"
      },
      "source": [
        "## **Process Description/How code was written/Sourcing etc**\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93097bfe",
      "metadata": {
        "id": "93097bfe"
      },
      "source": [
        "<font color='Green'><b>\n",
        "\n",
        "Using the above written practice questions as guidance, the following layout is used to describe the process:\n",
        "1. The code I used in this Jupyter Notebook was sourced or writen by me and the existing cells information, where necessary.\n",
        "\n",
        "2. As per the professional steps carried out in real-world, I filled/completed these cells in the following order:\n",
        "    - Step 1: Data Input\n",
        "    - Step 2: Data Processing (No action was required by me)\n",
        "    - Step 3: Implement Machine Learning Model\n",
        "    - Step 4: Validate Model\n",
        "    - Step 5: Visualize Results\n",
        "    - Answring the questions\n",
        "\n",
        "3. No, I did not use generative AI for this. I manually wrote it based on the requirements.\n",
        "\n",
        "</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c6de86",
      "metadata": {
        "id": "f7c6de86"
      },
      "source": [
        "# **Part 2: Classification**\n",
        "\n",
        "Developing code that can help the user classify different wine samples. Following the machine learning workflow, we will write the relevant code in each of the steps below:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f9d33a8",
      "metadata": {
        "id": "5f9d33a8"
      },
      "source": [
        "## **Step 1:** Data Input\n",
        "\n",
        "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
        "\n",
        "Using the pandas library to load the dataset. And then defining the column headers if they are not included in the dataset. We will then split the dataset into feature matrix `X` and target vector `y` and print the size and type of `X` and `y`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "33583c67",
      "metadata": {
        "id": "33583c67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2314 & 178\n"
          ]
        }
      ],
      "source": [
        "# Import wine dataset\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# Load the wine dataset\n",
        "wine = fetch_ucirepo(id=109)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = wine.data.features\n",
        "y = wine.data.targets\n",
        "\n",
        "# Print the shape of the dataset\n",
        "print(X.size, '&', y.size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156db208",
      "metadata": {
        "id": "156db208"
      },
      "source": [
        "## **Step 2:** Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a28af110",
      "metadata": {
        "id": "a28af110"
      },
      "source": [
        "Printing the first five rows of the dataset to inspect:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ea266921",
      "metadata": {
        "id": "ea266921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
            "0    14.23       1.71  2.43               15.6        127           2.80   \n",
            "1    13.20       1.78  2.14               11.2        100           2.65   \n",
            "2    13.16       2.36  2.67               18.6        101           2.80   \n",
            "3    14.37       1.95  2.50               16.8        113           3.85   \n",
            "4    13.24       2.59  2.87               21.0        118           2.80   \n",
            "\n",
            "   Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
            "0        3.06                  0.28             2.29             5.64  1.04   \n",
            "1        2.76                  0.26             1.28             4.38  1.05   \n",
            "2        3.24                  0.30             2.81             5.68  1.03   \n",
            "3        3.49                  0.24             2.18             7.80  0.86   \n",
            "4        2.69                  0.39             1.82             4.32  1.04   \n",
            "\n",
            "   0D280_0D315_of_diluted_wines  Proline  \n",
            "0                          3.92     1065  \n",
            "1                          3.40     1050  \n",
            "2                          3.17     1185  \n",
            "3                          3.45     1480  \n",
            "4                          2.93      735   \n",
            "\n",
            "    class\n",
            "0      1\n",
            "1      1\n",
            "2      1\n",
            "3      1\n",
            "4      1\n"
          ]
        }
      ],
      "source": [
        "print(X.head(5), '\\n\\n', y.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "834fc8fe",
      "metadata": {
        "id": "834fc8fe"
      },
      "source": [
        "Checking to see if there are any missing values in the dataset. If necessary, selecting an appropriate method to fill-in the missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "97c6e9dc",
      "metadata": {
        "id": "97c6e9dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alcohol                         0\n",
            "Malicacid                       0\n",
            "Ash                             0\n",
            "Alcalinity_of_ash               0\n",
            "Magnesium                       0\n",
            "Total_phenols                   0\n",
            "Flavanoids                      0\n",
            "Nonflavanoid_phenols            0\n",
            "Proanthocyanins                 0\n",
            "Color_intensity                 0\n",
            "Hue                             0\n",
            "0D280_0D315_of_diluted_wines    0\n",
            "Proline                         0\n",
            "dtype: int64 \n",
            "\n",
            " class    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(X.isnull().sum(), '\\n\\n', y.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "070956af",
      "metadata": {
        "id": "070956af"
      },
      "source": [
        "Samples we have for each type of wine:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b37a6fd9",
      "metadata": {
        "id": "b37a6fd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class\n",
            "2        71\n",
            "1        59\n",
            "3        48\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e6c46f",
      "metadata": {
        "id": "70e6c46f"
      },
      "source": [
        "## **Step 3:** Implement Machine Learning Model\n",
        "\n",
        "1. Importing `SVC` and `DecisionTreeClassifier` from sklearn\n",
        "2. Instantiating models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
        "3. Implementing the machine learning model with `X` and `y`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0870b0d2",
      "metadata": {
        "id": "0870b0d2"
      },
      "source": [
        "## **Step 4:** Validate Model\n",
        "\n",
        "Calculating the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, we will use `scoring='accuracy'`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb0bbd83",
      "metadata": {
        "id": "bb0bbd83"
      },
      "source": [
        "## **Step 5:** Visualize Results\n",
        "\n",
        "### **Step 5.1:** Compare Models\n",
        "1. Creating a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
        "2. Adding the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
        "3. Printing `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "be4b5c0a",
      "metadata": {
        "id": "be4b5c0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Training accuracy  Validation accuracy\n",
            "SVC           0.719101             0.651685\n",
            "DTC           1.000000             0.904494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Muneeb Ali\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Muneeb Ali\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Instantiating the models\n",
        "svc_model = SVC(random_state=0)\n",
        "dtc_model = DecisionTreeClassifier(max_depth=3)\n",
        "\n",
        "# Defining the scoring metric for cross-validation (repetitive code)\n",
        "scoring_var = 'accuracy'\n",
        "\n",
        "# Performing cross-validation for each model\n",
        "svc_scores = cross_validate(svc_model, X, y, scoring=scoring_var, cv=2, return_train_score=True)\n",
        "dtc_scores = cross_validate(dtc_model, X, y, scoring=scoring_var, cv=2, return_train_score=True)\n",
        "\n",
        "# Results for the training and validation accuracy\n",
        "svc_train = svc_scores['train_score'].mean()\n",
        "dtc_train = dtc_scores['train_score'].mean()\n",
        "\n",
        "svc_test = svc_scores['test_score'].mean()\n",
        "dtc_test = dtc_scores['test_score'].mean()\n",
        "\n",
        "# Storing the results in a list\n",
        "tmp_results_test = [svc_test, dtc_test]\n",
        "tmp_results_train = [svc_train, dtc_train]\n",
        "new_results_test, new_results_train = [], []\n",
        "\n",
        "# Looping through the results and appending them to the list\n",
        "for i in range(len(tmp_results_test)):\n",
        "    new_results_train.append(tmp_results_train[i])\n",
        "    new_results_test.append(tmp_results_test[i])\n",
        "\n",
        "# Creating a pandas DataFrame to store the results\n",
        "results = pd.DataFrame({\"Training accuracy\": new_results_train, \"Validation accuracy\": new_results_test}, index=['SVC', 'DTC'])\n",
        "\n",
        "# Printing the results\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2e17878",
      "metadata": {
        "id": "f2e17878"
      },
      "source": [
        "### **Step 5.2:** Visualize Classification Errors\n",
        "Using the method with highest accuracy to print the confusion matrix and classification report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "44b091a4",
      "metadata": {
        "id": "44b091a4"
      },
      "outputs": [],
      "source": [
        "# Implement best model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Using the best model\n",
        "best_model = dtc_model\n",
        "\n",
        "# Fitting the best model\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "09d21b59",
      "metadata": {
        "id": "09d21b59"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print confusion matrix using a heatmap\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix using a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=[\"1\",\"2\",\"3\"], yticklabels=[\"1\",\"2\",\"3\"])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5ef95947",
      "metadata": {
        "id": "5ef95947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      1.00      0.97        14\n",
            "           2       1.00      0.94      0.97        16\n",
            "           3       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.98      0.98      0.98        36\n",
            "weighted avg       0.97      0.97      0.97        36\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf319621",
      "metadata": {
        "id": "bf319621"
      },
      "source": [
        "## **Practice descriptive questions & answers for theoratical understanding**\n",
        "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
        "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
        "1. How many samples were incorrectly classified in step 5.2?\n",
        "1. In this case, is maximizing precision or recall more important? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1FQstcwnXXng",
      "metadata": {
        "id": "1FQstcwnXXng"
      },
      "source": [
        "<font color='Green'><b>\n",
        "1. Training accuracy came out to be better for tree based model as compared to support vector machines model, as observed in above cells. The training accuracy for the Decision Tree (DT) model was 1.000000 but for the Support Vector (SVC) model, it is very poor of 0.719101 which is underfitting perhaps. As for validation accuracies, the Decision Tree (DT) model attained 0.921348 but for the Support Vector (SVC) model, it is 0.651685 which is also very poor. Even in this case, the tree-based model is performing better than the support vector machines model. Refer to the results printed in the above cells or the copy of results printed below.\n",
        "\n",
        "   ```\n",
        "            Training accuracy  Validation accuracy\n",
        "   SVC               0.719101             0.651685\n",
        "   DTC               1.000000             0.921348\n",
        "   ```\n",
        "\n",
        "2. The support vector machines model did not work as well as the tree-based model possibly due to the following reasons:\n",
        "   - SVC is not able to capture the complex and non-linear relationships in the data.\n",
        "   - SVC is sensitive to the choice of the kernel and the hyperparameters so it might not be tuned properly.\n",
        "\n",
        "3. The number of samples that were incorrectly classified in step 5.2 is 1 in `Actual` of index mentioned `2`. Refer to the confusion matrix printed in the above cells or the copy of confusion matrix printed below.\n",
        "\n",
        "   ```\n",
        "   [ 14  0  0 ]\n",
        "   [ 1  15  0 ]\n",
        "   [ 0   0  6 ]\n",
        "   ```\n",
        "\n",
        "4. Even though both of them are crucial but in this case, maximizing recall is more important than precision. Since we want to minimize the number of false negatives, we want to make sure that we are able to correctly identify all the positive samples, even if it means that we have a few false positives. Maximizing precision would mean that model will be certain of whatever it predicts, but it will miss out on a lot of positive samples. \n",
        "\n",
        "</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "664ff8ae",
      "metadata": {
        "id": "664ff8ae"
      },
      "source": [
        "## **Process Description/How code was written/Sourcing etc**\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e837da",
      "metadata": {
        "id": "d0e837da"
      },
      "source": [
        "<font color='Green'><b>\n",
        "\n",
        "Using the above written practice questions as guidance, the following layout is used to describe the process:\n",
        "1. The code I used in this Jupyter Notebook was sourced or writen by me and the existing cells information, where necessary.\n",
        "\n",
        "2. As per the professional steps carried out in real-world, I filled/completed these cells in the following order:\n",
        "    - Step 1: Data Input\n",
        "    - Step 2: Data Processing\n",
        "    - Step 3: Implement Machine Learning Model\n",
        "    - Step 4: Validate Model\n",
        "    - Step 5: Visualize Results and compare models\n",
        "    - Answring the questions\n",
        "\n",
        "3. No, I did not use generative AI for this. I manually wrote it based on the requirements.\n",
        "\n",
        "</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa21e53b",
      "metadata": {
        "id": "fa21e53b"
      },
      "source": [
        "## **Part 3:** LinearSVC\n",
        "\n",
        "Repeating Part 2 and comparing the support vector machines model used to `LinearSVC(max_iter=5000)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "30fea72e",
      "metadata": {
        "id": "30fea72e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            Training accuracy  Validation accuracy\n",
            "Linear SVC           0.820225             0.797753\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Muneeb Ali\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Muneeb Ali\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "C:\\Users\\Muneeb Ali\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\Muneeb Ali\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Instantiating the LinearSVC model\n",
        "linear_svc_model = LinearSVC(max_iter=5000, random_state=0)\n",
        "scoring_var = 'accuracy'\n",
        "\n",
        "# Performing cross-validation for LinearSVC model\n",
        "linear_svc_scores = cross_validate(linear_svc_model, X, y, scoring=scoring_var, cv=2, return_train_score=True)\n",
        "\n",
        "# Results for the training and validation accuracy\n",
        "linear_svc_train = linear_svc_scores['train_score'].mean()\n",
        "linear_svc_test = linear_svc_scores['test_score'].mean()\n",
        "\n",
        "train_results, validation_results = [], []\n",
        "train_results.append(linear_svc_train)\n",
        "validation_results.append(linear_svc_test)\n",
        "\n",
        "# Creating a pandas DataFrame to store the results\n",
        "results = pd.DataFrame({\"Training accuracy\": train_results, \"Validation accuracy\": validation_results}, index=['Linear SVC'])\n",
        "\n",
        "# Printing the results\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aabc68a4",
      "metadata": {
        "id": "aabc68a4"
      },
      "source": [
        "<font color='Green'><b> NOTE:\n",
        "\n",
        "Using `LinearSVC` improves the results. Training accuracy jumped from 0.719101 to 0.820225 and Validation accuracy jumped from 0.651685 to 0.797753. It helps a little but not as much as we would have expected since model is still underfitting. And withou scaling the features, it is not a good fit for this dataset at this point. Refer to the results printed in the above cells or the copy of results printed below.\n",
        "\n",
        "```\n",
        "               Training accuracy  Validation accuracy\n",
        "SVC                     0.719101             0.651685\n",
        "Linear SVC              0.820225             0.797753\n",
        "```\n",
        "\n",
        "</b></font>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
